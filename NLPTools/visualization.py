#Andrei Simion 2018

#This creates some nice visualizations for the news' document embeddings
#using the Tensorflow embedding projector (https://projector.tensorflow.org/)
#Should also work with local Tensorflow and its projector

import gensim
import networkx as nx
import numpy as np
from elasticSearchWrapper import createESDict, extractData
from elasticsearch_dsl.connections import connections
import gensim.scripts.word2vec2tensor
from preprocessing import initLematizer, createStopwordsSet
from doc2vec import doc2VecWrapper

    
#creates tsv for document similarity using word embeddings
#(in our case, trained altogether with the document embeddings if dm != 0)
def createW2VTensorflowTSV(esDict, modelPath):
    d2vWrapper = doc2VecWrapper()
    d2vWrapper.loadDoc2VecModel(modelPath)

    #consider not hardcoding the path
    w2vTensorPlot = open('doc2vec_models/news_plot_tensor_w2v.tsv','w', encoding='utf8')
    metaPlot = open('doc2vec_models/news_plot_metadata_w2v.tsv','w', encoding='utf8')
    metaPlot.write('Titles\tPublications\tArticles\n')
   
    #start lemmas & stopwords
    lemmaDict = initLematizer()
    stopwords = createStopwordsSet()

    i = 0
    for articleLabel in d2vWrapper.d2vModel.docvecs.doctags:
        if articleLabel in esDict:
            if i % 1000:
                print(i)
            i += 1
            publication, title, headline, text = extractData(esDict, articleLabel)

            #create doc vector for text
            docVector = d2vWrapper.createDocumentEmbeddingW2V(text, lemmaDict, stopwords)

            #write in plot relevant info, consider adding pub date as well?
            metaPlot.write("%s\t%s\t%s\n" % (title, publication, headline))

            docVector = str(docVector)[1:-1]
            docVector = docVector.replace(', ', '\t')

            w2vTensorPlot.write(docVector + "\n")
            
    metaPlot.close()
    w2vTensorPlot.close()



#created for doc2vec document embedding visualization
#used to remove the unnecessary vectors generated by the
#word2vec2tensor.py script imported locally
def createD2VTensorflowTSV(esDict, modelPath):

    d2vModel = gensim.models.doc2vec.Doc2Vec.load(modelPath + 'doc2vec_model')
   
    metaPlot = open(modelPath + 'news_plot_metadata.tsv','w', encoding='utf8')

    #we read the tensors as generated by the script, however, some of
    #the labels contained in this plot are unneeded by our comparisons   
    #some of the labels aka the auxiliary training documents used
    tensorPlot = open(modelPath + 'news_plot_tensor.tsv','r+', encoding='utf8')
    metaPlot.write('Titles\tPublications\tArticles\n')
    tensorLines = tensorPlot.readlines()

    #the meta file is replaced completely, but we only replace
    #unneeded vectors from the tensor file
    tensorReplacement = open(modelPath + 'news_plot_tensor_r.tsv','w', encoding='utf8')

    for i, articleLabel in enumerate(d2vModel.docvecs.doctags):
        #check if data in elastic
        if articleLabel in esDict:
        
            publication, title, headline, _ = extractData(esDict, articleLabel)

            #write in plot relevant info, consider adding pub date as well?
            metaPlot.write("%s\t%s\t%s\n" % (title, publication, headline))
            tensorReplacement.write(tensorLines[i])

    metaPlot.close()
    tensorPlot.close()

if __name__ == "__main__":

    #doc2vec path for dm = 1, distributed memory model used
    dmD2VModelPath = 'doc2vec_models/classic, dm + dm_concat = 0/'
    
    #doc2vec path for dm = 0, distributed bag of words model used
    dbowD2VModelPath = 'doc2vec_models/dbow + dm_concat = 0/'

    #load doc2vec model and save it as word2vec for the word2vec2tensor.py
    #d2vModel = gensim.models.doc2vec.Doc2Vec.load(dbowD2VModelPath + 'doc2vec_model')
    #d2vModel.save_word2vec_format(dbowD2VModelPath + 'doc_tensor.w2v', doctag_vec=True, word_vec=False)

    esDict = createESDict()
    createD2VTensorflowTSV(esDict, dbowD2VModelPath)
    #createW2VTensorflowTSV(esDict, dmD2VModelPath + "doc2vec_model")