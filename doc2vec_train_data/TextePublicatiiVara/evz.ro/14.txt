Comentarii | 23 Vizualizari
Folosind o procedura de „deep learning” cercetatorii americani de la MIT au reusit sa dezvolte o inteligenta artificiala care este capabila sa recunoasca sunetele – vorbirea sau muzica – la fel de bina ca si noi.
In  filmul american „Her” Theodore Twombly dezvolta o relaitie cu Samantha, un sistem de operare inteligent, care vorbeste cu el prin intermediul unei voci feminine. In realitate insa, cat de aproape suntem de dezvoltarea unei inteligente artificiale capabile sa converseze cu noi, sa ne „inteleaga” si sa ne raspunda? La ora actula vorbim cu Siri – asistentul/a virtual creat de Apple – insa Siri este foarte limitat – nu conversam de fapt cu Siri ci cerem informatii dntr-o baza de date.
Vom ajunge oare sa conversam cu un computer, cu o inteligenta artificiala care sa ne inteleaga si sa ne raspunda? Se pare ca suntem un pas mai aproape de acest obiectiv in urma rezultatelor unui proiect realizat de neurologii de la MIT, SUA, care, pentru prima data, au dezvoltat o inteligenta artificiala capabila sa reproduca capacitatea oamenilor de a recunoaste si intelege muzica si vorvirea. Rezultatele acestui studiu au fost publicate recent in revista Neuron.
Cercetatorii de la MIT au folosit o procedura de deep-learning (invatare profunda) denumita „deep neural network” (retea neuronala profunda). Procedura prevede mai multe straturi de procesare a informatiei in mai multe unitati care pot fi antrenate cu informatii specifice obiectivului si care este inclusiv folosita de cercetatori pentru a intelege mai bine cum functioneaza creierul nostru. Aplicarea acestei proceduri este destul de complicata datorita faptului ca inca nu exista un model teoretic perfect care sa descrie ceea ce se intampla.
Procedura de retea neuronala profunda a fost dezvoltata inca din anii ’80, insa la vremea respectiva nu existau calculatoare destul de performante pentru a realiza modele capabile sa recunoasca muzica sau vorbirea. In ultimii ani, o data cu cresterea capacitatii de calcul si a tehnologiilor la baza deep-learningului, au fost puse bazele mai multor aplicatii mai ales in ingineria industriala. Iata insa ca neurologii, tinand cont de nuutatile din acest domeniu, au reluat activitatea de dezvoltare a inteligentei artificiale in cadrul acestui noi proiect in care au antrenat o retea neuronala pentru recunoasterea a doua tipuri de sunete: vorbire si muzica.
Pentru a realiza acest ambitios obiectiv reteaua neuronala a fost antrenata cu mii de inregistrari, de durata a doua secunde fiecare, de persoane care vorbesc. Scopul era de a se reusi recunoasterea cuvintelor pronuntate la jumatatea inregistrarilor, chiar si atunci cand acestea erau efectuate intr-un mediu zgomotos – la fel ca si in viata reala atunci cand vorim cu altii si suntem mai mereu inconjurati de alte persoane care vorbesc sau de sunete care provin de la trafic, diverse aparate, sau alte activitati. Pentru antrenamentul muzical au fost folosite mii de inregistrari de durata de doua secunde cu obiectivul de a se reusi pe urma recunoasterea clipului. Si in aceasta situatie fiecare inregistrare muzicala continea un zgomot de fond, ceea cea ingreunat procedura de recunoatere.
